<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Fairness Assessment #    Dataset: We consider a standard test case for fair learning: the Broward County recidivism dataset, popularized by ProPublica. The data set contains 6,172 instances and 14 numeric features (created by one-hot encoding the categorical features in the initial seven feature data set). 20% are held for testing.
  Classifiers: The task is to predict whether a person will commit a crime within two years (two-year recidivism).">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="Fairness Assessment" />
<meta property="og:description" content="Fairness Assessment #    Dataset: We consider a standard test case for fair learning: the Broward County recidivism dataset, popularized by ProPublica. The data set contains 6,172 instances and 14 numeric features (created by one-hot encoding the categorical features in the initial seven feature data set). 20% are held for testing.
  Classifiers: The task is to predict whether a person will commit a crime within two years (two-year recidivism)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/docs/use_cases/case2/" /><meta property="article:section" content="docs" />



<title>Fairness Assessment | My New Hugo Site</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.e246e6a45b940b6ff71d8216783f10a80d910290a7c364c8bfd5d305d8545d62.css" integrity="sha256-4kbmpFuUC2/3HYIWeD8QqA2RApCnw2TIv9XTBdhUXWI=">
<script defer src="/en.search.min.2a2f435221fb9bbbb5f32da04c13848349ead433cdea1e79f659a124646665b1.js" integrity="sha256-Ki9DUiH7m7u18y2gTBOEg0nq1DPN6h559lmhJGRmZbE="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a href="/"><span>My New Hugo Site</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  



  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Introduction</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/introduction/overall_introduction/" class="">Overall Introduction</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <span>Publication</span>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/publication/paper/" class="">Paper</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/publication/video/" class="">Video</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/publication/demo/" class="">Demo</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/docs/user_guide/" class="">User Guide</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/user_guide/get_started/" class="">Get Started</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/user_guide/other_usage/" class="">Views Manipulation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/user_guide/view_description/" class="">Descriptions of Views</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/user_guide/data_preparation/" class="">Data Preparation</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/docs/use_cases/" class="">Use Case</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case3/" class="">Bias and Data Discovery</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case2/" class=" active">Fairness Assessment</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case5/" class="">Feature Sensitivity Testing</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case6/" class="">Model Selection</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case1/" class="">Model Selection and Data Discovery</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case4/" class="">Model Selection and Tuning</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case7/" class="">(Continuous) Hyper parameter Tuning</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case8/" class="">(Continuous) Data Examination</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case9/" class="">(Continuous) Model Selection</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/use_cases/case20/" class="">(Continuous) Model Selection and Detail Examination</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Fairness Assessment</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#fairness-assessment"><strong>Fairness Assessment</strong></a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h3 id="fairness-assessment">
  <strong>Fairness Assessment</strong>
  <a class="anchor" href="#fairness-assessment">#</a>
</h3>
<ul>
<li>
<p>Dataset:
We consider a standard test case for fair learning: the Broward County recidivism dataset, popularized by ProPublica. The data set contains 6,172 instances and 14 numeric features (created by one-hot encoding the categorical features in the initial seven feature data set). 20% are held for testing.</p>
</li>
<li>
<p>Classifiers: The task is to predict whether a person will commit a crime within two years (two-year recidivism). Classifiers built for this problem are often unfair in that they skew errors towards racial and gender bias. We consider three classifiers trained on the data, a baseline random forest, and two hand-tuned variants (C3 and Pos).</p>
</li>
<li>
<p>Walkthrough:</p>
<p>First, click the button on the top left and load the dataset.
<img src="../../../../../image/fair-1.png" alt="Example image" /></p>
<p>Since we are comparing within a specific category - race, we need to select data by category. To do this, we should open <em>Histogram</em> view and click the arrow at the top right corner of the view. A dropdown menu will appear. Select the category &ldquo;race&rdquo;.
<img src="../../../../../image/fair-2.png" alt="Example image" /></p>
<p>In order to see whether classifiers perform fairly when dealing with different races, we should pick two kinds of races to select in <em>Histogram</em> view. Left click the bar labeled &ldquo;Caucasian&rdquo; and right click the one labeled &ldquo;African-American&rdquo; and they will be highlighted with cyan and magenta respectively.
<img src="../../../../../image/fair-3.png" alt="Example image" /></p>
<!-- raw HTML omitted -->
<p>Then we can use <em>Selection Performance</em> view to see the fairness achieved by each classifier.
We can first see the &ldquo;accuracy&rdquo; achieved by each classifier based on two selection (left view). Then we can choose to display the &ldquo;precision&rdquo; (middle) and &ldquo;recall&rdquo; (right) by selecting relative buttons on the panel.
<img src="../../../../../image/fair-4.png" alt="Example image" /></p>
<p>We can find that while <em>Selection Performance</em> view shows similar accuracies for the selections, the precision and recall are very different. In addition,  C3 has high precision but low recall for &ldquo;Caucasians&rdquo;, and high recall but low precision for &ldquo;African-Americans&rdquo;. That is, its errors are biased to predict no for &ldquo;Caucasians&rdquo; and yes for &ldquo;African-Americans&rdquo;. While other classifiers make more errors, their errors are more uniformly distributed. To further compare classifiers based on their prediction profile per class, we can apply <em>Confusion Matrix Grid</em> here:
<img src="../../../../../image/fair-5.png" alt="Example image" /></p>
<p>To explore further, we consider the effect of gender. We open another <em>Histogram</em> view, expand the panel above, choose &ldquo;gender&rdquo; :
<img src="../../../../../image/fair-6.png" alt="Example image" />
Then, we select the subset of female instances by using &ldquo;left-click&rdquo; in a histogram (left view) and intersect this with the African American subset (right view: using the relationship widget).
<img src="../../../../../image/fair-7.png" alt="Example image" /></p>
<p>Back to the <em>Selection Performance</em> view and choose to display the &ldquo;recall&rdquo;, we can notice C3 has very 0 recall on this subset of African American females, while other classifiers achieve more balanced performance.
<img src="../../../../../image/fair-8.png" alt="Example image" /></p>
</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#fairness-assessment"><strong>Fairness Assessment</strong></a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












